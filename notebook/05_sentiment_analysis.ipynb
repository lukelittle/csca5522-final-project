{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Sentiment Analysis with RoBERTa\n",
    "\n",
    "**Author:** Lucas Little  \n",
    "**Course:** CSCA 5522: Data Mining Project  \n",
    "**University:** University of Colorado - Boulder\n",
    "\n",
    "This notebook implements sentiment analysis using a RoBERTa model fine-tuned on Twitter data to analyze samples of cryptocurrency-related tweets.\n",
    "\n",
    "## Objectives\n",
    "1. Load cleaned tweet data samples\n",
    "2. Implement RoBERTa-based sentiment analysis on each sample\n",
    "3. Aggregate sentiment scores into 15-minute windows for each sample\n",
    "4. Save sentiment-enriched datasets for feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Note\n",
    "To quickly validate the data processing pipeline and the overall thesis, this notebook uses a smaller, faster model (`cardiffnlp/twitter-roberta-base-sentiment-latest`) on a one-week sample of the data. This allows for rapid iteration and verification before committing to the full, computationally expensive analysis with the FinBERT model on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n",
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n",
      "MPS available: True\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Sentiment analysis imports\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize RoBERTa-based Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing Twitter sentiment model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ cardiffnlp/twitter-roberta-base-sentiment-latest model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def initialize_sentiment_model():\n",
    "    \"\"\"\n",
    "    Initialize a RoBERTa model fine-tuned for Twitter sentiment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"ü§ñ Initializing Twitter sentiment model...\")\n",
    "        model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "        device = -1\n",
    "        if torch.cuda.is_available():\n",
    "            device = 0\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = 'mps'\n",
    "            \n",
    "        sentiment_pipeline = pipeline(\n",
    "            \"sentiment-analysis\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ {model_name} model loaded successfully!\")\n",
    "        return sentiment_pipeline, \"roberta_twitter\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load the model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "sentiment_pipeline, model_type = initialize_sentiment_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Process Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Sample 1 ---\n",
      "üîç Analyzing sentiment for 2,072 tweets in sample 1 using roberta_twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:22<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment analysis complete!\n",
      "üìÖ Aggregating sentiment by 15-minute windows...\n",
      "‚úÖ Created 15-minute aggregation: 672 periods\n",
      "üíæ Saving aggregated sentiment dataset...\n",
      "‚úÖ Saved 15-minute sentiment data: ../data/processed/sampled/sentiment_sample_1.csv\n",
      "\n",
      "--- Processing Sample 2 ---\n",
      "üîç Analyzing sentiment for 240 tweets in sample 2 using roberta_twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:02<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment analysis complete!\n",
      "üìÖ Aggregating sentiment by 15-minute windows...\n",
      "‚úÖ Created 15-minute aggregation: 665 periods\n",
      "üíæ Saving aggregated sentiment dataset...\n",
      "‚úÖ Saved 15-minute sentiment data: ../data/processed/sampled/sentiment_sample_2.csv\n",
      "\n",
      "--- Processing Sample 3 ---\n",
      "üîç Analyzing sentiment for 2,820 tweets in sample 3 using roberta_twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 45/45 [00:34<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment analysis complete!\n",
      "üìÖ Aggregating sentiment by 15-minute windows...\n",
      "‚úÖ Created 15-minute aggregation: 673 periods\n",
      "üíæ Saving aggregated sentiment dataset...\n",
      "‚úÖ Saved 15-minute sentiment data: ../data/processed/sampled/sentiment_sample_3.csv\n",
      "\n",
      "--- Processing Sample 4 ---\n",
      "üîç Analyzing sentiment for 2,973 tweets in sample 4 using roberta_twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 47/47 [00:30<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment analysis complete!\n",
      "üìÖ Aggregating sentiment by 15-minute windows...\n",
      "‚úÖ Created 15-minute aggregation: 673 periods\n",
      "üíæ Saving aggregated sentiment dataset...\n",
      "‚úÖ Saved 15-minute sentiment data: ../data/processed/sampled/sentiment_sample_4.csv\n",
      "\n",
      "--- Processing Sample 5 ---\n",
      "üîç Analyzing sentiment for 7,663 tweets in sample 5 using roberta_twitter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 120/120 [01:38<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Sentiment analysis complete!\n",
      "üìÖ Aggregating sentiment by 15-minute windows...\n",
      "‚úÖ Created 15-minute aggregation: 673 periods\n",
      "üíæ Saving aggregated sentiment dataset...\n",
      "‚úÖ Saved 15-minute sentiment data: ../data/processed/sampled/sentiment_sample_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sentiment_scores(texts, pipeline_model, batch_size=64):\n",
    "    \"\"\"\n",
    "    Analyze sentiment for a list of texts in batches.\n",
    "    \"\"\"\n",
    "    if pipeline_model is None:\n",
    "        return [(0.0, 0.0)] * len(texts)\n",
    "    \n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Analyzing sentiment\"):\n",
    "        batch = [str(t)[:512] for t in texts[i:i+batch_size]]\n",
    "        try:\n",
    "            batch_results = pipeline_model(batch)\n",
    "            for res in batch_results:\n",
    "                label = res['label'].lower()\n",
    "                score = res['score']\n",
    "                if 'positive' in label:\n",
    "                    polarity = score\n",
    "                elif 'negative' in label:\n",
    "                    polarity = -score\n",
    "                else:\n",
    "                    polarity = 0.0\n",
    "                results.append(polarity)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {e}\")\n",
    "            results.extend([0.0] * len(batch))\n",
    "            \n",
    "    return results\n",
    "\n",
    "data_dir = Path('../data')\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "sampled_dir = processed_data_dir / 'sampled'\n",
    "\n",
    "if model_type:\n",
    "    for i in range(1, 6):\n",
    "        print(f\"\\n--- Processing Sample {i} ---\")\n",
    "        tweet_sample_path = sampled_dir / f'tweets_sample_{i}.csv'\n",
    "        \n",
    "        if not tweet_sample_path.exists():\n",
    "            print(f\"‚ö†Ô∏è Sample {i} not found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        tweets_df = pd.read_csv(tweet_sample_path)\n",
    "        tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'])\n",
    "        \n",
    "        print(f\"üîç Analyzing sentiment for {len(tweets_df):,} tweets in sample {i} using {model_type}...\")\n",
    "        sentiments = get_sentiment_scores(tweets_df['text'].tolist(), sentiment_pipeline)\n",
    "        tweets_df['sentiment'] = sentiments\n",
    "        print(\"‚úÖ Sentiment analysis complete!\")\n",
    "        \n",
    "        print(\"üìÖ Aggregating sentiment by 15-minute windows...\")\n",
    "        tweets_df.set_index('timestamp', inplace=True)\n",
    "        \n",
    "        agg_config = {\n",
    "            'sentiment': ['mean', 'var', 'count'],\n",
    "            'retweet_count': 'sum',\n",
    "            'like_count': 'sum'\n",
    "        }\n",
    "        \n",
    "        sentiment_15min = tweets_df.resample('15T').agg(agg_config)\n",
    "        sentiment_15min.columns = ['_'.join(col).strip() for col in sentiment_15min.columns]\n",
    "        sentiment_15min.reset_index(inplace=True)\n",
    "        \n",
    "        sentiment_15min['sentiment_momentum'] = sentiment_15min['sentiment_mean'].diff()\n",
    "        sentiment_15min['sentiment_var'] = sentiment_15min['sentiment_var'].fillna(0)\n",
    "        sentiment_15min['sentiment_momentum'] = sentiment_15min['sentiment_momentum'].fillna(0)\n",
    "        \n",
    "        print(f\"‚úÖ Created 15-minute aggregation: {len(sentiment_15min)} periods\")\n",
    "        \n",
    "        print(\"üíæ Saving aggregated sentiment dataset...\")\n",
    "        output_path = sampled_dir / f'sentiment_sample_{i}.csv'\n",
    "        sentiment_15min.to_csv(output_path, index=False)\n",
    "        print(f\"‚úÖ Saved 15-minute sentiment data: {output_path}\")\n",
    "else:\n",
    "    print(\"Sentiment model not available. Skipping analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
