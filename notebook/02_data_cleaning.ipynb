{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data Cleaning\n",
    "\n",
    "**Author:** Lucas Little  \n",
    "**Course:** CSCA 5522: Data Mining Project  \n",
    "**University:** University of Colorado - Boulder\n",
    "\n",
    "This notebook cleans the preprocessed tweet and price data to ensure that all timestamps are in the correct format.\n",
    "\n",
    "## Objectives\n",
    "1. Load the preprocessed tweet and price data\n",
    "2. Identify and remove rows with invalid timestamp formats\n",
    "3. Save the cleaned data to new files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Loading preprocessed data...\n",
      "Loaded 17,298,735 tweets\n",
      "Loaded 7,103,245 price records\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "data_dir = Path('../data')\n",
    "processed_data_dir = data_dir / 'processed'\n",
    "\n",
    "print(\"ðŸ“Š Loading preprocessed data...\")\n",
    "tweets_df = pd.read_csv(processed_data_dir / 'tweets_processed.csv')\n",
    "prices_df = pd.read_csv(processed_data_dir / 'prices_processed.csv')\n",
    "\n",
    "print(f\"Loaded {len(tweets_df):,} tweets\")\n",
    "print(f\"Loaded {len(prices_df):,} price records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and Normalize Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning tweet timestamps...\n",
      "Removed 29 rows with invalid timestamps from tweets data.\n",
      "Cleaning price timestamps...\n",
      "Removed 0 rows with invalid timestamps from price data.\n",
      "Normalizing timezones...\n",
      "Timestamps normalized to UTC (timezone-naive).\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaning tweet timestamps...\")\n",
    "initial_rows = len(tweets_df)\n",
    "tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'], errors='coerce')\n",
    "tweets_df.dropna(subset=['timestamp'], inplace=True)\n",
    "final_rows = len(tweets_df)\n",
    "print(f\"Removed {initial_rows - final_rows:,} rows with invalid timestamps from tweets data.\")\n",
    "\n",
    "print(\"Cleaning price timestamps...\")\n",
    "initial_rows = len(prices_df)\n",
    "prices_df['timestamp'] = pd.to_datetime(prices_df['timestamp'], errors='coerce')\n",
    "prices_df.dropna(subset=['timestamp'], inplace=True)\n",
    "final_rows = len(prices_df)\n",
    "print(f\"Removed {initial_rows - final_rows:,} rows with invalid timestamps from price data.\")\n",
    "\n",
    "print(\"Normalizing timezones...\")\n",
    "# Convert both to UTC first to preserve time relationships\n",
    "if tweets_df['timestamp'].dt.tz is not None:\n",
    "    tweets_df['timestamp'] = tweets_df['timestamp'].dt.tz_convert('UTC')\n",
    "else:\n",
    "    tweets_df['timestamp'] = tweets_df['timestamp'].dt.tz_localize('UTC')\n",
    "\n",
    "if prices_df['timestamp'].dt.tz is not None:\n",
    "    prices_df['timestamp'] = prices_df['timestamp'].dt.tz_convert('UTC')\n",
    "else:\n",
    "    prices_df['timestamp'] = prices_df['timestamp'].dt.tz_localize('UTC')\n",
    "\n",
    "# Now remove timezone info from both (they're now synchronized)\n",
    "tweets_df['timestamp'] = tweets_df['timestamp'].dt.tz_localize(None)\n",
    "prices_df['timestamp'] = prices_df['timestamp'].dt.tz_localize(None)\n",
    "\n",
    "print(\"Timestamps normalized to UTC (timezone-naive).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Saving cleaned data...\n",
      "âœ… Saved cleaned tweets: ../data/processed/tweets_cleaned.csv\n",
      "âœ… Saved cleaned prices: ../data/processed/prices_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ’¾ Saving cleaned data...\")\n",
    "tweet_output_path = processed_data_dir / 'tweets_cleaned.csv'\n",
    "tweets_df.to_csv(tweet_output_path, index=False)\n",
    "print(f\"âœ… Saved cleaned tweets: {tweet_output_path}\")\n",
    "\n",
    "price_output_path = processed_data_dir / 'prices_cleaned.csv'\n",
    "prices_df.to_csv(price_output_path, index=False)\n",
    "print(f\"âœ… Saved cleaned prices: {price_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
